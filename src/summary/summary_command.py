import discord
from discord import app_commands
from discord.ext import commands 
import json
import logging
from src.llm import LLM
from src.summary.summary_aux import parse_user_ids , RateLimitingScheduler , Summary_fetch_task
from src.summary.summary_ui import summary_check_view
from typing import List, Optional
from src.config import LLM_FORMAT , LLM_ALLOW_CHANNELS
import asyncio
import time
import re

log = logging.getLogger(__name__)


class summarizerCog(commands.Cog):
    def __init__(self,bot: commands.Bot):
        self.bot = bot
        self.scheduler = RateLimitingScheduler(bot)
        self.scheduler_task : Optional[asyncio.Task] = None
        self.cache_task: Optional[asyncio.Task] = None
        try:
            self.llm = LLM()
            logging.info("Summary Cog loaded")
        except Exception as e:
            self.llm = None
            logging.error(f"Failed to load Summary Cog: {e}")

    def cog_load(self):
            logging.debug("Scheduler task is starting.")
            self.scheduler_task = self.bot.loop.create_task(self.scheduler.run())
            self.cache_task = self.bot.loop.create_task(self.scheduler.queue_cache_event())
    
    def cog_unload(self):
        logging.debug("Scheduler task is being cancelled.")
        if self.scheduler_task:
            self.scheduler_task.cancel()
        if self.cache_task:
            self.cache_task.cancel()

    summary_group = app_commands.Group(name="summary",description="æ–‡æœ¬æ‘˜è¦ç›¸å…³å‘½ä»¤")
    @summary_group.command(name="å¸¸è§„",description="ä»URLè‡ªä¸‹å¾€ä¸Šè·å–ç‰¹å®šæ¡æ•°çš„æ¶ˆæ¯è¿›è¡Œæ€»ç»“")
    @app_commands.describe(
        url = "æœ€ç»ˆçš„æ¶ˆæ¯é“¾æ¥",
        message_length = "å°†è¦è·å–çš„ä¸Šä¸‹æ–‡æ¡æ•°",
        members = "(å¯é€‰)è‹¥å¡«å†™æ­¤é¡¹ï¼Œåˆ™åªæœ‰è¿™äº›æˆå‘˜çš„æ¶ˆæ¯ä¼šè¢«æ€»ç»“ï¼Œç›´æ¥atå³å¯"
    )
    async def summary(self, interaction: discord.Integration , url: str , message_length: int,members: str=None):
        current_channel_id = interaction.channel_id
        # è·å–çˆ¶é¢‘é“ ID (å¦‚æœå½“å‰æ˜¯ Thread/å­åŒºï¼Œåˆ™ parent_id ä¸ä¸ºç©º)
        parent_id = getattr(interaction.channel, "parent_id", None)

        # æ£€æŸ¥å½“å‰é¢‘é“æˆ–å…¶çˆ¶é¢‘é“æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­
        if current_channel_id not in LLM_ALLOW_CHANNELS and parent_id not in LLM_ALLOW_CHANNELS:
            await interaction.response.send_message(
                f"âŒ æƒé™ä¸è¶³ï¼šå½“å‰é¢‘é“ (ID: {current_channel_id}) æœªè¢«æˆæƒä½¿ç”¨ AI æ€»ç»“åŠŸèƒ½ã€‚",
                ephemeral=True
            )
            return
        await interaction.response.defer(ephemeral=True)
        user_ids = parse_user_ids(members)
        match = re.match(r'https://discord.com/channels/(\d+)/(\d+)/(\d+)', url)
        if not match:
            await interaction.followup.send(
                f"âŒ æä¾›çš„URLæ ¼å¼æ— æ•ˆã€‚è¯·æä¾›ä¸€æ¡å®Œæ•´çš„æ¶ˆæ¯é“¾æ¥ã€‚",
                ephemeral=True
            )
            return
        guild_id,channel_id,message_id = match.groups()
        current_task = Summary_fetch_task(
            timestamp=time.time(),
            target_channel=int(channel_id),
            fetch_total=message_length,
            single_limit=min(message_length,100),
            start_before_message_id=message_id
        )
        try:
            estimated_time_s = await self.scheduler.estimate_completion_time(current_task)
            estimated_time_str = f"{estimated_time_s:.2f} ç§’"
            if estimated_time_s > 60:
                estimated_time_str = f"{estimated_time_s} ç§’ (çº¦{float(estimated_time_s / 60):.2f} åˆ†é’Ÿ)"
        except Exception as e:
            estimated_time_s = "æ— æ³•ä¼°è®¡æ—¶é—´ (Error:{e})"
        if members == None:
            members = "ä¸Šä¸‹æ–‡ä¸­çš„**å…¨éƒ¨æˆå‘˜**"
        embed_title = "â­•|SummaryäºŒæ¬¡ç¡®è®¤"
        embed_text = f"""
        ğŸ”—|[èµ·å§‹ç‚¹]({url})
        ğŸ”¼|æ¶ˆæ¯æ¡æ•°:{message_length}
        ğŸ™â€â™‚ï¸|å‘½ä»¤æŒ‡å®šçš„æˆå‘˜: {members}
        â³|é¢„è®¡æ—¶é—´: {estimated_time_str}
        """

        embed = discord.Embed(title=embed_title,description=embed_text,color=discord.Color.blue())
        check_view = summary_check_view()

        await interaction.edit_original_response(embed=embed,view=check_view)
        await check_view.wait()

        if check_view.value is not True:
            if check_view.value is None:
                await interaction.edit_original_response(content="â²|æ“ä½œè¶…æ—¶ï¼Œå·²å–æ¶ˆ",view=None)
                return
            await interaction.edit_original_response(content=f"å·²å–æ¶ˆï¼Œæ‚¨å¯ä»¥ä¿®æ”¹æ‚¨çš„å‘½ä»¤å†æ¬¡å‘é€\n```\n/summary å¸¸è§„ url:{url} message_length:{message_length} members:{members}\n```",view=None)
            return
        try:
            await self.scheduler.main_queue.put(current_task)
            self.scheduler.rate_limit_event.set()

            message: List[discord.Message] = await asyncio.wait_for(current_task.future,timeout=600)

            if not message:
                await interaction.edit_original_response(content="ğŸŸ¡ | æœªèƒ½è·å–åˆ°ä»»ä½•æ¶ˆæ¯ï¼Œè¯·æ£€æŸ¥é¢‘é“æƒé™æˆ–é“¾æ¥æ˜¯å¦æ­£ç¡®ã€‚", view=None)
                return
            
            await interaction.edit_original_response(embed=discord.Embed(
                title="âš™ï¸|æ­£åœ¨å¤„ç†",
                description=f"å·²æˆåŠŸè·å– {len(message)} æ¡æ¶ˆæ¯ï¼Œæ­£åœ¨è¿›è¡Œ AI æ€»ç»“...",
                color=discord.Color.green()
            ),view=None)

            from src.summary.summary_aux import parse_message_history_to_prompt, openai_format
            from src.chat.gemini_format import gemini_format_callback
            
            if LLM_FORMAT == "gemini":
                # è·å– contents ç»“æ„
                final_data = await parse_message_history_to_prompt(
                    message=message,
                    post_processing_callback=gemini_format_callback,
                    members_ids=user_ids if user_ids else None
                )
                payload_list = final_data.get("contents", [])
                
                # è½¬æ¢ System Prompt ä¸º Gemini æ ¼å¼
                from src.summary.summary_env import SYSTEM_PROMPT
                
                gemini_system = {
                    "systemInstruction": {
                        "parts": [{"text": SYSTEM_PROMPT}]
                    }
                }
                payload_list.insert(0, gemini_system)
            else:
                # åŸæœ‰çš„ OpenAI å¤„ç†é€»è¾‘
                final_prompt = await parse_message_history_to_prompt(
                    message=message,
                    post_processing_callback=openai_format,
                    members_ids=user_ids if user_ids else None
                )
                payload_list = final_prompt.get("messages", [])
                from src.summary.summary_env import system_prompt
                payload_list.insert(0, system_prompt)

            llm_input_json = json.dumps(payload_list, ensure_ascii=False)
            logging.debug(f"llm_input_json:\n {llm_input_json}")
            try:
                llm_result = await self.llm.llm_call(llm_input_json)
                summary_chunks = llm_result["chunks"]
                if not summary_chunks:
                    await interaction.edit_original_response(content="âŒ | AI æœªèƒ½ç”Ÿæˆä»»ä½•æ€»ç»“å†…å®¹ã€‚")
                    return
                 # 1. é¦–å…ˆæ›´æ–°ä¹‹å‰çš„ç§å¯†ä¿¡æ¯ï¼Œå‘ŠçŸ¥ç”¨æˆ·å·²å®Œæˆ
                await interaction.edit_original_response(
                    content="âœ… | æ€»ç»“å·²å®Œæˆï¼Œç»“æœå·²å‘é€è‡³é¢‘é“ä¸­ã€‚", 
                    embed=None, 
                    view=None
                )

                # 2. æ„é€ ä¸» Embed
                main_embed = discord.Embed(
                    title="ğŸ“ | èŠå¤©æ‘˜è¦æŠ¥å‘Š",
                    description=summary_chunks[0],
                    color=discord.Color.gold()
                )
                main_embed.set_footer(text=f"åˆ†æäº† {len(message)} æ¡æ¶ˆæ¯ | æ¨¡å¼: {LLM_FORMAT}")
                
                # 3. ä½¿ç”¨ followup.send å¹¶ä¸”è®¾ç½® ephemeral=False (é»˜è®¤å°±æ˜¯ Falseï¼Œä½†ä¸ºäº†æ˜ç¡®å¯ä»¥åŠ ä¸Š)
                # è¿™æ¡æ¶ˆæ¯é¢‘é“å†…æ‰€æœ‰äººå¯è§
                await interaction.followup.send(content=f"{interaction.user.mention} æäº¤çš„æ€»ç»“æŠ¥å‘Šï¼š", embed=main_embed, ephemeral=False)

                # 4. å¦‚æœæœ‰åç»­åˆ†æ®µï¼ŒåŒæ ·å…¬å¼€å‘é€
                for i in range(1, len(summary_chunks)):
                    next_embed = discord.Embed(
                        description=summary_chunks[i],
                        color=discord.Color.gold()
                    )
                    await interaction.followup.send(embed=next_embed, ephemeral=False)

            except Exception as e:
                # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œä¾ç„¶åœ¨ç§å¯†æ¶ˆæ¯ä¸­åé¦ˆ
                log.error(f"LLM è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
                await interaction.edit_original_response(content=f"âŒ | è°ƒç”¨ AI æ—¶å‡ºé”™: {str(e)}", view=None)

        except asyncio.TimeoutError:
            await interaction.edit_original_response(content="âŒ | å¤„ç†è¶…æ—¶ï¼ˆæ¶ˆæ¯æŠ“å–æˆ– AI å“åº”è¿‡æ…¢ï¼‰ã€‚")
        except Exception as e:
            log.error(f"å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            await interaction.edit_original_response(content=f"âŒ | ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")